{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "\n",
    "from models.superpoint import SuperPoint\n",
    "from models.superglue import SuperGlue\n",
    "from models.utils import frame2tensor\n",
    "\n",
    "\n",
    "# 디바이스 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# SuperPoint 및 SuperGlue 모델 로드\n",
    "def load_superpoint_superglue_models():\n",
    "    # SuperPoint 설정\n",
    "    superpoint_config = {\n",
    "        'nms_radius': 4,\n",
    "        'keypoint_threshold': 0.005,\n",
    "        'max_keypoints': -1\n",
    "    }\n",
    "    superpoint = SuperPoint(superpoint_config).to(device).eval()\n",
    "\n",
    "    # SuperGlue 설정\n",
    "    superglue_config = {\n",
    "        'weights': 'indoor',  # 이미지에 따라 'outdoor'로 변경 가능\n",
    "        'sinkhorn_iterations': 20,\n",
    "        'match_threshold': 0.2\n",
    "    }\n",
    "    superglue = SuperGlue(superglue_config).to(device).eval()\n",
    "\n",
    "    return superpoint, superglue\n",
    "\n",
    "superpoint, superglue = load_superpoint_superglue_models()\n",
    "\n",
    "# 이미지 경로 설정\n",
    "img_path = '/home/hyuneun/disk_b/ESL/SfM/sfm/data/nutellar2/'\n",
    "\n",
    "img1_name = 'nutella4.jpg'\n",
    "img2_name = 'nutella5.jpg'\n",
    "img3_name = 'nutella6.jpg'\n",
    "img4_name = 'nutella7.jpg'\n",
    "\n",
    "# 이미지 대비 조절 함수\n",
    "def adjust_contrast(img, alpha=1.2, beta=20):\n",
    "    return cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "\n",
    "# 이미지 로드 함수\n",
    "def load_image(img_path, img1_name, img2_name, contrast=False):\n",
    "    img1 = cv2.imread(img_path + img1_name)\n",
    "    img2 = cv2.imread(img_path + img2_name)\n",
    "    \n",
    "    if img1 is None:\n",
    "        raise FileNotFoundError(f\"Error: Unable to load image {img1_name} from {img_path}\")\n",
    "    if img2 is None:\n",
    "        raise FileNotFoundError(f\"Error: Unable to load image {img2_name} from {img_path}\")\n",
    "    \n",
    "    # 대비 조절 (원할 경우)\n",
    "    if contrast:\n",
    "        img1 = adjust_contrast(img1)\n",
    "        img2 = adjust_contrast(img2)\n",
    "    \n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return img1, img2\n",
    "\n",
    "# SuperPoint와 SuperGlue를 사용한 특징점 추출 및 매칭 함수\n",
    "def SuperPoint_SuperGlue(img1, img2):\n",
    "    # 이미지를 그레이스케일로 변환\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # 이미지를 텐서로 변환\n",
    "    img1_tensor = frame2tensor(img1_gray, device)\n",
    "    img2_tensor = frame2tensor(img2_gray, device)\n",
    "\n",
    "    # SuperPoint로 특징점 추출\n",
    "    with torch.no_grad():\n",
    "        pred1 = superpoint({'image': img1_tensor})\n",
    "        pred2 = superpoint({'image': img2_tensor})\n",
    "\n",
    "    keypoints0 = pred1['keypoints'][0].cpu().numpy()\n",
    "    descriptors0 = pred1['descriptors'][0].cpu().numpy()\n",
    "    keypoints1 = pred2['keypoints'][0].cpu().numpy()\n",
    "    descriptors1 = pred2['descriptors'][0].cpu().numpy()\n",
    "\n",
    "    # 임의의 scores0, scores1을 추가 (SuperPoint에서 스코어가 없으므로 기본값으로 설정)\n",
    "    scores0 = torch.ones(keypoints0.shape[0]).unsqueeze(0).to(device)  # 크기 맞춰 임의의 스코어 설정\n",
    "    scores1 = torch.ones(keypoints1.shape[0]).unsqueeze(0).to(device)  # 크기 맞춰 임의의 스코어 설정\n",
    "    \n",
    "\n",
    "    # SuperGlue를 위한 데이터 준비\n",
    "    input_data = {\n",
    "        'keypoints0': torch.tensor(keypoints0).unsqueeze(0).to(device),\n",
    "        'keypoints1': torch.tensor(keypoints1).unsqueeze(0).to(device),\n",
    "        'descriptors0': torch.tensor(descriptors0).unsqueeze(0).to(device),\n",
    "        'descriptors1': torch.tensor(descriptors1).unsqueeze(0).to(device),\n",
    "        'scores0': scores0,  # 추가된 scores0\n",
    "        'scores1': scores1,  # 추가된 scores1\n",
    "        'image0': img1_tensor,\n",
    "        'image1': img2_tensor,\n",
    "    }\n",
    "\n",
    "\n",
    "    # SuperGlue로 매칭 수행\n",
    "    with torch.no_grad():\n",
    "        pred = superglue(input_data)\n",
    "\n",
    "    matches = pred['matches0'][0].cpu().numpy()\n",
    "    confidence = pred['matching_scores0'][0].cpu().numpy()\n",
    "\n",
    "    # 매칭된 특징점 추출\n",
    "    valid = matches > -1\n",
    "    mkpts0 = keypoints0[valid]\n",
    "    mkpts1 = keypoints1[matches[valid]]\n",
    "    mconf = confidence[valid]\n",
    "\n",
    "    # cv2.KeyPoint 객체 생성\n",
    "    img1_kp = [cv2.KeyPoint(x=float(kp[0]), y=float(kp[1]), size=1) for kp in keypoints0]\n",
    "    img2_kp = [cv2.KeyPoint(x=float(kp[0]), y=float(kp[1]), size=1) for kp in keypoints1]\n",
    "\n",
    "    # cv2.DMatch 객체 생성\n",
    "    matches_good = []\n",
    "    for idx, (queryIdx, trainIdx, conf) in enumerate(zip(np.where(valid)[0], matches[valid], mconf)):\n",
    "        match = cv2.DMatch(_queryIdx=queryIdx, _trainIdx=trainIdx, _imgIdx=0, _distance=1 - conf)\n",
    "        matches_good.append(match)\n",
    "\n",
    "    # 매칭 결과 시각화\n",
    "    res = cv2.drawMatches(img1, img1_kp, img2, img2_kp, matches_good, None, flags=2)\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(res)\n",
    "    plt.show()\n",
    "\n",
    "    return matches_good, img1_kp, img2_kp\n",
    "\n",
    "# 에센셜 매트릭스 추정\n",
    "def Estimation_E(matches_good, img1_kp, img2_kp):\n",
    "    query_idx = [match.queryIdx for match in matches_good]\n",
    "    train_idx = [match.trainIdx for match in matches_good]\n",
    "    p1 = np.float32([img1_kp[ind].pt for ind in query_idx]) \n",
    "    p2 = np.float32([img2_kp[ind].pt for ind in train_idx])\n",
    "\n",
    "    E, mask = cv2.findEssentialMat(p1, p2, method=cv2.RANSAC, focal=3092.8, pp=(2016, 1512), maxIters=1000, threshold=0.3)\n",
    "    \n",
    "    p1_inlier = p1[mask.ravel() == 1]\n",
    "    p2_inlier = p2[mask.ravel() == 1]\n",
    "\n",
    "    return E, p1_inlier, p2_inlier\n",
    "\n",
    "# 에센셜 매트릭스 분해\n",
    "def EM_Decomposition(E, p1, p2):\n",
    "    U, S, VT = np.linalg.svd(E)\n",
    "    W = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n",
    "    if np.linalg.det(U) < 0:\n",
    "        U *= -1\n",
    "    if np.linalg.det(VT) < 0:\n",
    "        VT *= -1\n",
    "\n",
    "    camera_matrix_options = [\n",
    "        np.column_stack((U @ W @ VT, U[:, 2])),\n",
    "        np.column_stack((U @ W @ VT, -U[:, 2])),\n",
    "        np.column_stack((U @ W.T @ VT, U[:, 2])),\n",
    "        np.column_stack((U @ W.T @ VT, -U[:, 2]))\n",
    "    ]\n",
    "\n",
    "    # 카메라 매트릭스 선택 (여기서는 첫 번째 사용)\n",
    "    return camera_matrix_options[0]\n",
    "\n",
    "# 내부 카메라 행렬 초기화\n",
    "def initialize_CM(CameraMatrix):\n",
    "    Rt0 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "    skew = 0.0  # 왜곡 계수는 0으로 설정\n",
    "    K = np.array([[3092.8, skew, 2016], [0, 3092.8, 1512], [0, 0, 1]])\n",
    "    Rt1 = K @ CameraMatrix\n",
    "    return Rt0, Rt1\n",
    "\n",
    "# 삼각측량\n",
    "def LinearTriangulation(Rt0, Rt1, p1, p2):\n",
    "    A = np.array([\n",
    "        p1[1] * Rt0[2, :] - Rt0[1, :],\n",
    "        p1[0] * Rt0[2, :] - Rt0[0, :],\n",
    "        p2[1] * Rt1[2, :] - Rt1[1, :],\n",
    "        p2[0] * Rt1[2, :] - Rt1[0, :]\n",
    "    ])\n",
    "\n",
    "    _, _, VT = np.linalg.svd(A)\n",
    "    X = VT[-1]\n",
    "    return X[0:3] / X[3]\n",
    "\n",
    "# 3D 포인트 생성\n",
    "def make_3dpoint(p1, p2, Rt0, Rt1):\n",
    "    p3ds = []\n",
    "    for pt1, pt2 in zip(p1, p2):\n",
    "        p3d = LinearTriangulation(Rt0, Rt1, pt1, pt2)\n",
    "        p3ds.append(p3d)\n",
    "    return np.array(p3ds).T\n",
    "\n",
    "# 3D 시각화\n",
    "def visualize_3d(p3ds):\n",
    "    X = p3ds[0]\n",
    "    Y = p3ds[1]\n",
    "    Z = p3ds[2]\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.scatter3D(X, Y, Z, c='b', marker='o') \n",
    "    plt.show()\n",
    "\n",
    "# 좌표계 맞춤\n",
    "def align_coordinate_system(Rt1_first, Rt1_second):\n",
    "    R_first = Rt1_first[:, :3]\n",
    "    R_second = Rt1_second[:, :3]\n",
    "    T = np.linalg.inv(R_first) @ R_second\n",
    "    return T\n",
    "\n",
    "# 2-view 재구성 함수\n",
    "def reconstruct_2view(img1_name, img2_name):\n",
    "    img1, img2 = load_image(img_path, img1_name, img2_name)\n",
    "    matches_good, img1_kp, img2_kp = SuperPoint_SuperGlue(img1, img2)\n",
    "    E, p1_inlier, p2_inlier = Estimation_E(matches_good, img1_kp, img2_kp)\n",
    "    CameraMatrix = EM_Decomposition(E, p1_inlier, p2_inlier)\n",
    "    Rt0, Rt1 = initialize_CM(CameraMatrix)\n",
    "    point3d = make_3dpoint(p1_inlier, p2_inlier, Rt0, Rt1)\n",
    "    return point3d, Rt1\n",
    "\n",
    "# 여러 2-view 결합\n",
    "def reconstruct_4view():\n",
    "    p3ds_12, Rt1_first = reconstruct_2view(img1_name, img2_name)\n",
    "    p3ds_23, Rt1_second = reconstruct_2view(img2_name, img3_name)\n",
    "    p3ds_34, Rt1_third = reconstruct_2view(img3_name, img4_name)\n",
    "    p3ds_41, Rt1_fourth = reconstruct_2view(img4_name, img1_name)\n",
    "    \n",
    "    # 좌표계 맞춤\n",
    "    T1 = align_coordinate_system(Rt1_first, Rt1_second)\n",
    "    p3ds_23_transformed = T1 @ p3ds_23\n",
    "    T2 = align_coordinate_system(Rt1_first, Rt1_third)\n",
    "    p3ds_34_transformed = T2 @ p3ds_34\n",
    "    T3 = align_coordinate_system(Rt1_first, Rt1_fourth)\n",
    "    p3ds_41_transformed = T3 @ p3ds_41\n",
    "    \n",
    "    # 모든 포인트 합치기\n",
    "    p3ds_combined = np.hstack((p3ds_12, p3ds_23_transformed, p3ds_34_transformed, p3ds_41_transformed))\n",
    "\n",
    "    # 3D 시각화\n",
    "    print(\"3D 포인트 계산 완료, 시각화 시작\")\n",
    "    visualize_3d(p3ds_combined)\n",
    "\n",
    "# 4-view 재구성 실행\n",
    "reconstruct_4view()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
